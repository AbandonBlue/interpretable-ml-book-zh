# 第八章 水晶球

可解释机器学习的未来是什么？这一章是一个推测性的心理练习和一个主观的猜测如何解释机器学习将发展。我以相当悲观的态度打开了这本书，并希望以一种更加乐观的态度结束这本书。

我的“预测”基于三个前提：

\1.    数字化：任何（有趣的）信息都将数字化。想想电子现金和在线交易。想想电子书、音乐和视频。想想关于我们的环境、人类行为、工业生产过程等的所有感官数据。所有东西数字化的驱动因素包括：廉价的计算机/传感器/存储、规模效应（赢家全力以赴）、新的商业模式、模块化的价值链、成本压力等等。

\2.    自动化：当一个任务可以被自动化，并且自动化的成本低于一段时间内执行该任务的成本时，该任务将被自动化。甚至在引进计算机之前，我们已经有了一定程度的自动化。例如，织机自动编织或蒸汽机自动马力。但是计算机和数字化将自动化带到了下一个层次。简单地说，您可以编程forloops、编写Excel宏、自动化电子邮件响应等等，这就显示了个人可以自动化的程度。自动售票机可以自动购买火车票（不再需要出纳），洗衣机可以自动洗衣，定期订单可以自动付款等。自动化任务可以腾出时间和金钱，因此有一个巨大的经济和个人动机来实现自动化。我们目前正在观察语言翻译、驾驶的自动化，甚至在很小程度上观察科学发现。

\3.    错误的指定：我们不能用它的所有约束完美地指定一个目标。想象一个瓶子里的精灵，它总是按照字面意思表达你的愿望：“我想成为世界上最富有的人！“->你成为最富有的人，但作为副作用，你持有的货币因通货膨胀而崩溃。

“我想快乐地度过余生！“->在接下来的5分钟里，你感到非常高兴，然后精灵杀死了你。

“我祝愿世界和平！“->精灵杀死所有人。

我们错误地指定目标，要么是因为我们不知道所有的约束，要么是因为我们无法度量它们。让我们把公司看作是不完善目标规范的一个例子。公司的简单目标是为股东赚钱。但是，这个规范并没有捕捉到真正的目标和我们真正努力追求的所有约束：例如，我们不欣赏一家公司为了赚钱而杀人，毒害河流，或者仅仅打印自己的钱。我们发明了法律、法规、制裁、合规程序、工会等来修补不完善的目标规范。另一个你可以亲身体验的例子是一个游戏，你玩一台机器，目的是生产尽可能多的回形针。警告：它会上瘾。我不想把它搞得太糟，但让我们说事情很快就失控了。在机器学习中，目标规范中的缺陷来自不完善的数据抽象（偏态总体、测量误差等）、不受约束的损失函数、对约束缺乏了解、训练数据和应用数据之间分布的转移等等。

数字化正在推动自动化。不完善的目标规范与自动化冲突。我声称，这种冲突部分是通过解释方法来调解的。

我们预测的舞台已经准备好了，水晶球已经准备好了，现在我们来看看这个领域的发展方向！

8.1机器学习的未来

没有机器学习就没有可解释的机器学习。因此，在讨论可解释性之前，我们必须猜测机器学习的方向。

机器学习（或“人工智能”）与许多承诺和期望有关。但是，让我们从一个不那么乐观的观察开始：虽然科学开发了许多奇特的机器学习工具，但根据我的经验，很难将它们集成到现有的过程和产品中。不是因为这不可能，而是因为公司和机构需要时间来赶上。在当前人工智能炒作的淘金热中，公司开设了“人工智能实验室”、“机器学习单元”和“数据科学家”、“机器学习专家”、“人工智能工程师”等等，但现实是，在我的经验中，相当令人沮丧。通常情况下，公司甚至没有所需格式的数据，数据科学家们会等待数月。有时公司对人工智能和数据科学有如此高的期望，因为媒体使得数据科学家永远无法实现它们。通常没有人知道如何将数据科学家整合到现有的结构和许多其他问题中。这导致了我的第一个预言。

机器学习会缓慢而稳定地成长。

数字化正在推进，自动化的诱惑也在不断地拉动。即使机器学习采用的道路是缓慢和坚如磐石的，机器学习也在不断地从科学转向商业过程、产品和现实世界的应用。

我认为我们需要更好地向非专家解释什么类型的问题可以被表述为机器学习问题。我认识许多高薪的数据科学家，他们通过报表和SQL查询来执行Excel计算或经典的商业智能，而不是应用机器学习。但一些公司已经成功地使用了机器学习，而大型互联网公司则处于最前沿。我们需要找到更好的方法将机器学习整合到流程和产品中，培训人员并开发易于使用的机器学习工具。我相信机器学习将变得更加容易使用：我们已经看到机器学习变得越来越容易使用，例如通过云服务（“机器学习作为一种服务”），只需在周围添加一些流行词。一旦机器学习成熟了——这个刚学走路的孩子已经迈出了第一步——我的下一个预测是：

机器学习会带来很多东西。

根据“任何可以自动化的东西都是自动化的”的原则，我得出结论，只要可能，任务将被制定为预测问题，并通过机器学习来解决。机器学习是自动化的一种形式，或者至少可以是其中的一部分。目前由人类执行的许多任务都被机器学习所取代。以下是一些任务示例，其中机器学习用于自动化部分任务：

•  文件的整理/决策/完成（如保险公司、立法部门或咨询公司）

•  数据驱动的决策，如信贷应用程序

•  药物发现

•  装配线的质量控制

•  自动驾驶汽车

•  疾病诊断

•  翻译。在这本书中，我使用了一个名为（由深度神经网络支持的）的翻译服务，通过将句子从英语翻译成德语，然后再翻译成英语来改进我的句子。

•  …

机器学习的突破不仅是通过更好的计算机/更多的数据/更好的软件实现的，还包括：

可解释性工具促进机器学习的采用。

基于机器学习模型的目标永远不能被完美地指定的前提，可以解释的机器学习是必要的，以弥补错误指定和实际目标之间的差距。在许多领域和部门，可解释性将成为采用机器学习的催化剂。一些轶事证据：我和许多人交谈过，他们不使用机器学习，因为他们不能向其他人解释模型。我相信，可解释性将解决这个问题，使机器学习对需要某种透明度的组织和人员具有吸引力。除了对问题的错误描述，许多行业还需要可解释性，无论是出于法律原因，还是出于风险规避，或是为了深入了解基础任务。

机器学习使建模过程自动化，使人类远离数据和底层任务：这增加了实验设计、培训分布选择、采样、数据编码、特征工程等问题的风险。解释工具使识别这些问题更加容易。

8.2可解释性的未来

让我们来看看机器学习可解释性可能的未来。

重点是模型不可知论解释工具。

当它与底层机器学习模型分离时，自动化可解释性就容易得多。模型不可知解释的优点在于其模块性。我们可以很容易地替换底层的机器学习模型。我们可以很容易地取代解释方法。基于这些原因，模型不可知论方法将有更好的扩展性。这就是为什么我相信模型不可知论方法将在长期内变得更占主导地位。但本质上可解释的方法也会有一席之地。

机器学习将是自动化的，有了它，就可以解释。

一个已经明显的趋势是模型培训的自动化。这包括自动化工程和特性选择、自动超参数优化、不同模型的比较以及模型的集成或叠加。结果是最佳预测模型。当我们使用模型不可知论解释方法时，我们可以自动将它们应用于从自动化机器学习过程中出现的任何模型。在某种程度上，我们也可以自动化第二步：自动计算特征重要性、绘制部分依赖关系、训练代理模型等等。没有人阻止您自动计算所有这些模型解释。实际的解释仍然需要人。想象一下：你上传一个数据集，指定预测目标，然后按下一个按钮，最佳的预测模型就会得到训练，程序会给出模型的所有解释。已经有了第一批产品，我认为对于许多应用程序来说，使用这些自动化机器学习服务就足够了。今天，任何人都可以在不了解HTML、CSS和JavaScript的情况下创建网站，但周围仍然有许多Web开发人员。同样，我相信每个人都可以在不知道如何编程的情况下训练机器学习模型，而且仍然需要机器学习专家。

我们不分析数据，我们分析模型。

原始数据本身总是无用的。（我故意夸大。事实上，你需要对数据有一个深刻的理解来进行有意义的分析。）我不关心数据；我关心数据中包含的知识。可解释机器学习是从数据中提取知识的一种很好的方法。您可以广泛地探测模型，模型自动识别特征是否和如何与预测相关（许多模型都有内置的特征选择），模型可以自动检测关系的表示方式，如果经过正确的训练，最终模型是一个非常很好地接近现实。

许多分析工具已经基于数据模型（因为它们基于分布假设）：

•  像学生t检验一样的简单假设检验。

•  调整混杂因素的假设检验（通常是GLMS）

•  方差分析（方差分析）

•  相关系数（标准化线性回归系数与

皮尔逊相关系数）

•  …

我在这里告诉你的并不是什么新鲜事。那么，为什么要从分析基于假设的透明模型转向分析无假设的黑盒模型呢？因为做出所有这些假设都是有问题的：它们通常是错误的（除非你相信世界上大多数地方都遵循高斯分布），难以检查，非常不灵活，很难自动化。在许多领域，基于假设的模型对未接触测试数据的预测性能通常比黑盒机器学习模型差。这只适用于大数据集，因为具有良好假设的可解释模型在小数据集上的性能通常比黑盒模型好。黑盒机器学习方法需要大量的数据才能很好地工作。随着所有事物的数字化，我们将拥有更大的数据集，因此机器学习的方法变得更具吸引力。我们不做假设，我们尽可能接近现实（同时避免过度拟合训练数据）。我认为我们应该开发统计学中的所有工具来回答问题（假设测试、相关度量、交互度量、可视化工具、置信区间、p值、预测区间、概率分布），并将它们改写为黑盒模型。在某种程度上，这已经发生了：

•  让我们采用一个经典的线性模型：标准化回归系数已经是一个重要的度量。有了，我们就有了一个可以与任何模型一起工作的工具。

•  在线性模型中，系数测量单个特征对预测结果的影响。这个的广义版本是。

•  测试A或B是否更好：为此，我们也可以使用偏相关函数。我们还没有（据我所知）对任意黑盒模型进行统计测试。

数据科学家将自动进行处理。

我相信，对于许多分析和预测任务，数据科学家最终会自动完成他们的工作。为了实现这一点，任务必须定义得很好，并且周围必须有一些流程和例程。如今，这些程序和过程已经不复存在，但数据科学家和同事们正在研究它们。随着机器学习成为许多行业和机构不可或缺的一部分，许多任务将自动化。

机器人和程序会自我解释。

我们需要更多直观的机器和程序接口，以充分利用机器学习。一些例子：一辆自动驾驶的汽车，它报告为什么突然停止（“70%的可能性，一个孩子会过马路”）；一个信用违约程序，解释了为什么信用申请被拒绝（“申请人有太多的信用卡，并受雇于一个不稳定的工作）。“）；一个机器人手臂，解释了为什么它将物品从传送带移到垃圾箱中（“物品底部有一种热”）。

可解释性可以促进机器智能研究。

我可以想象，通过对程序和机器如何解释自己进行更多的研究，我们可以提高对智能的理解，并更好地创建智能机器。

最后，所有这些预测都是推测，我们必须看看未来到底会带来什么。形成自己的观点，继续学习！